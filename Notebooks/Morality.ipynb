{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "import html\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "def preproc(text):\n",
    "    \n",
    "    modComm = text\n",
    "    #replace newlines with spaces\n",
    "    modComm = re.sub(r\"\\s+\", \" \", modComm)\n",
    "\n",
    "    modComm = html.unescape(modComm)\n",
    "\n",
    "    modComm = re.sub(r\"(http|www)\\S+\", \"\", modComm)\n",
    "        \n",
    "    modComm = ' '.join(modComm.split())\n",
    "\n",
    "    # get Spacy document for modComm\n",
    "    # use Spacy document for modComm to create a string.\n",
    "    doc = nlp(modComm)\n",
    "    modComm = \"\"\n",
    "    for sentence in doc.sents:\n",
    "        for token in sentence:\n",
    "            # Replace token with token.lemma\n",
    "            if token.text.startswith(\"-\") and (not token.lemma_.startswith(\"-\")):\n",
    "                content = token.lemma_\n",
    "            else:\n",
    "                content = token.text\n",
    "            \n",
    "            # Uppercase distinction\n",
    "            if token.text.isupper():\n",
    "                modComm += content.upper()\n",
    "            else:\n",
    "                modComm += content.lower()\n",
    "\n",
    "            # Write \"/POS\" after each token.\n",
    "            # Add the part-of-speech (pos) tag after the token text\n",
    "            # modComm += \"/\" + token.tag_\n",
    "            # Add a space after the token\n",
    "            # Split tokens with spaces.\n",
    "            modComm += \" \"\n",
    "        # Insert \"\\n\" between sentences.\n",
    "        # Add a newline character after the sentence\n",
    "        modComm += \"\\n\"\n",
    "    return modComm\n",
    "    # print(token.text, token.pos_, token.dep_)   \n",
    "    # print(modComm)\n",
    "\n",
    "directory = '/Users/akilhuang/Desktop/SUDS/NELA2021/NELA2021_0'\n",
    "files = os.listdir(directory)\n",
    "index = 0\n",
    "limit = len(files)\n",
    "# limit = 5\n",
    "output_data = []\n",
    "output_filename = 'output.json'  # Specify the output file name\n",
    "\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    while index < limit:\n",
    "        filename = files[index]\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(directory, filename)) as f:\n",
    "                # print(f.read())\n",
    "                output = dict()\n",
    "                output['id'] = index\n",
    "                output[\"body\"] = preproc(f.read())\n",
    "                output_data.append(output)\n",
    "\n",
    "\n",
    "        index += 1\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    json.dump(output_data, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m             sanctity_vice \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(s\u001b[39m.\u001b[39mgroup())\n\u001b[1;32m     95\u001b[0m         word_length\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> 97\u001b[0m care_virtue \u001b[39m=\u001b[39m care_virtue\u001b[39m/\u001b[39;49mword_length\n\u001b[1;32m     98\u001b[0m fairness_virtue \u001b[39m=\u001b[39m fairness_virtue\u001b[39m/\u001b[39mword_length\n\u001b[1;32m     99\u001b[0m loyalty_virtue \u001b[39m=\u001b[39m loyalty_virtue\u001b[39m/\u001b[39mword_length\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "\n",
    "mfd_dict = {}\n",
    "mfd_lst = [0, 44, 45, 46, 47,48,49,50,51,52,53]\n",
    "\n",
    "with open('../emfd_amp.csv', 'r') as file:\n",
    "        reader = csv.reader(file, delimiter=',', quotechar='|')\n",
    "        headers = next(reader, None)\n",
    "        # print(headers)\n",
    "        for row in reader:\n",
    "            row_dict = {headers[i]: row[i] for i in mfd_lst}\n",
    "            mfd_dict[row_dict[headers[0]]] = row_dict\n",
    "\n",
    "\n",
    "file_path = '/Users/akilhuang/Desktop/SUDS/output.json'\n",
    "\n",
    "# Open the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data\n",
    "    json_data = json.load(file)\n",
    "\n",
    "mfd_score = {}\n",
    "\n",
    "for i in range(len(json_data)):\n",
    "    care_virtue = 0.0\n",
    "    fairness_virtue = 0.0\n",
    "    loyalty_virtue = 0.0\n",
    "    authority_virtue = 0.0\n",
    "    sanctity_virtue = 0.0\n",
    "    \n",
    "    care_vice = 0\n",
    "    fairness_vice = 0\n",
    "    loyalty_vice = 0\n",
    "    authority_vice = 0\n",
    "    sanctity_vice = 0\n",
    "    # print(json_data[i])\n",
    "    # print(json_data[i]['body'])\n",
    "    word_length = 0\n",
    "    \n",
    "    for token in json_data[i]['body'].split():\n",
    "        if token in mfd_dict:\n",
    "            token_c = mfd_dict[token]['care.virtue']\n",
    "            token_f = mfd_dict[token]['fairness.virtue']\n",
    "            token_l = mfd_dict[token]['loyalty.virtue']\n",
    "            token_a = mfd_dict[token]['authority.virtue']\n",
    "            token_s = mfd_dict[token]['sanctity.virtue']\n",
    "\n",
    "            decimal_pattern = re.compile(r'\\d+\\.\\d+')\n",
    "            c = decimal_pattern.search(token_c)\n",
    "            f = decimal_pattern.search(token_f)\n",
    "            l = decimal_pattern.search(token_l)\n",
    "            a = decimal_pattern.search(token_a)\n",
    "            s = decimal_pattern.search(token_s)\n",
    "\n",
    "            if c:\n",
    "                care_virtue += float(c.group())\n",
    "            if f:\n",
    "                fairness_virtue += float(f.group())  \n",
    "            if l:\n",
    "                loyalty_virtue += float(l.group())  \n",
    "            if a:\n",
    "                authority_virtue += float(a.group())  \n",
    "            if s:\n",
    "                sanctity_virtue += float(s.group())\n",
    "            \n",
    "            token_c = mfd_dict[token]['care.vice']\n",
    "            token_f = mfd_dict[token]['fairness.vice']\n",
    "            token_l = mfd_dict[token]['loyalty.vice']\n",
    "            token_a = mfd_dict[token]['authority.vice']\n",
    "            token_s = mfd_dict[token]['sanctity.vice']\n",
    "\n",
    "            decimal_pattern = re.compile(r'\\d+\\.\\d+')\n",
    "            c = decimal_pattern.search(token_c)\n",
    "            f = decimal_pattern.search(token_f)\n",
    "            l = decimal_pattern.search(token_l)\n",
    "            a = decimal_pattern.search(token_a)\n",
    "            s = decimal_pattern.search(token_s)\n",
    "\n",
    "            if c:\n",
    "                care_vice += float(c.group())\n",
    "            if f:\n",
    "                fairness_vice += float(f.group())  \n",
    "            if l:\n",
    "                loyalty_vice += float(l.group())  \n",
    "            if a:\n",
    "                authority_vice += float(a.group())  \n",
    "            if s:\n",
    "                sanctity_vice += float(s.group())\n",
    "            word_length+=1\n",
    "    \n",
    "    care_virtue = care_virtue/word_length\n",
    "    fairness_virtue = fairness_virtue/word_length\n",
    "    loyalty_virtue = loyalty_virtue/word_length\n",
    "    authority_virtue = authority_virtue/word_length\n",
    "    sanctity_virtue = sanctity_virtue/word_length\n",
    "\n",
    "    care_vice = care_vice/word_length\n",
    "    fairness_vice = fairness_vice/word_length\n",
    "    loyalty_vice = loyalty_vice/word_length\n",
    "    authority_vice = authority_vice/word_length\n",
    "    sanctity_vice = sanctity_vice/word_length\n",
    "\n",
    "    mfd_score[i] = [care_virtue,fairness_virtue,loyalty_virtue, \n",
    "                    authority_virtue,sanctity_virtue, care_vice,\n",
    "                    fairness_vice, loyalty_vice, authority_vice,\n",
    "                    sanctity_vice]\n",
    "mfd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
